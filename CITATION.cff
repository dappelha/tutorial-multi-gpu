cff-version: 1.2.0
title: Efficient Distributed GPU Programming for Exascale
message: >-
  If you use this software, please cite it using the
  metadata from this file.
authors:
  - given-names: Andreas
    family-names: Herten
    email: a.herten@fz-juelich.de
    affiliation: JÃ¼lich Supercomputing Centre
    orcid: 'https://orcid.org/0000-0002-7150-2505'
  - given-names: Lena
    family-names: Oden
    email: lena.oden@fernuni-hagen.de
    affiliation: FernUni Hagen
    orcid: 'https://orcid.org/0000-0002-9670-5296'
  - given-names: Simon
    family-names: Garcia de Gonzalo
    email: simgarc@sandia.gov
    affiliation: Sandia National Laboratories
    orcid: 'https://orcid.org/0000-0002-5699-1793'
  - given-names: Jiri
    family-names: Kraus
    email: jkraus@nvidia.com
    affiliation: NVIDIA
    orcid: 'https://orcid.org/0000-0002-5240-3317'
  - given-names: Markus
    family-names: Hrywniak
    email: mhrywniak@nvidia.com
    affiliation: NVIDIA
    orcid: 'https://orcid.org/0000-0002-6015-8788'
  - given-names: David
    family-names: Appelhans
    email: dappelhans@nvidia.com
    affiliation: NVIDIA
    orcid: 'https://orcid.org/0000-0003-1433-9198'
identifiers:
  - type: doi
    value: 10.5281/zenodo.5745504
    description: Year-agnostic Zenodo Identifier
repository-code: 'https://github.com/FZJ-JSC/tutorial-multi-gpu/'
abstract: >-
  Over the past decade, GPUs became ubiquitous in HPC installations around the world, delivering the majority of performance of some of the largest supercomputers, steadily increasing the available compute capacity. Finally, four exascale systems are deployed (Frontier, Aurora, El Capitan, JUPITER), using GPUs as the core computing devices for this era of HPC.
  To take advantage of these GPU-accelerated systems with tens of thousands of devices, application developers need to have the proper skills and tools to understand, manage, and optimize distributed GPU applications.
  In this tutorial, participants will learn techniques to efficiently program large-scale multi-GPU systems. While programming multiple GPUs with MPI is explained in detail, also advanced tuning techniques and complementing programming models like NCCL and NVSHMEM are presented. Tools for analysis are shown and used to motivate and implement performance optimizations. The tutorial teaches fundamental concepts that apply to GPU-accelerated systems of any vendor in general, taking the NVIDIA platform as an example. It is a combination of lectures and hands-on exercises, using the JUPITER system for interactive learning and discovery.
keywords:
  - NVIDIA
  - GPU
  - CUDA
  - Exascale
  - MPI
  - NCCL
  - NVSHMEM
  - Distributed Programming
license: MIT
version: '9.0-sc25'
date-released: '2025-11-16'
